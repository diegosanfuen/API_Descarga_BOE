{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247e8196-12ee-4d1b-9f52-2bf3d6870eb2",
   "metadata": {},
   "source": [
    "# Descarga de información del BOE sobre ofertas de empleo para servir mediante API Flask\n",
    "\n",
    "Alumno: Diego Sánchez de la Fuente\n",
    "\n",
    "Firma: Aseguro que todo el contenido expuesto en la práctica es propio y no está copiado de ninguna otra fuente aunque se haya podido utilizar documentación para la inspiración del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de130fef-f6ea-400b-9532-7ddef72edc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib3 as url\n",
    "import datetime\n",
    "import string\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "import regex, re\n",
    "from flask import Flask, render_template, request, Response, jsonify #Utilidades para la construccion de un API Rest\n",
    "import warnings\n",
    "import os\n",
    "from flask import Flask, render_template, request, send_from_directory\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d78c1b-7226-4ab5-a873-341b37f0c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar antes del API Flask si se desea omitir la ejecución del modulo Scrapper\n",
    "df = pd.read_csv('datos_offline/datos_obtenidos.boe.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9564316-49c3-42f7-909c-de01f55c3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescargaBOE:\n",
    "    \"\"\"\n",
    "    Clase que permite la descarga del BOE en lo referente a las Resoluciones relacionadas con las convocatorias de Oposiciones\n",
    "    Para instanciar la clase:\n",
    "    MiClase = DescsargaBOE()\n",
    "    Para fijar el Offset\n",
    "    MiClase.establecer_offset(offset)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Generador de la clase no recibe parámetros\n",
    "        establece las variables internas\n",
    "        fecha_actual, url_patron, dominio u dataset con los boes\n",
    "        \"\"\"\n",
    "        # Obtiene la fecha y hora actual\n",
    "        self.fecha_actual = datetime.datetime.now()\n",
    "        self.url_patron = string.Template(\"https://www.boe.es/boe/dias/$anio/$mes/$dia/index.php?s=2B\")\n",
    "        self.dominio = \"https://www.boe.es\"\n",
    "        self.dataset_boes = pd.DataFrame({'url':[], \n",
    "                                          'titulo':[],\n",
    "                                          'texto':[]})\n",
    "        self.user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59\"\n",
    "        self.timeout = 100\n",
    "        \n",
    "\n",
    "    def quitar_etiquetas_html(self, cadena_html: str) -> str:\n",
    "        \"\"\"\n",
    "        Método Helper para la eliminación de etiquetas HTML de los textos parseados\n",
    "        uso:\n",
    "        Entrada: Texto con etiquetas HTML\n",
    "        Salida: Mismo Texto sin etiquetas HTML\n",
    "        self.quitar_etiquetas_html(Texto)\n",
    "        \"\"\"\n",
    "        # Parsear la cadena HTML\n",
    "        soup = BeautifulSoup(cadena_html, 'html.parser')    \n",
    "        # Obtener solo el texto sin etiquetas HTML\n",
    "        texto = soup.get_text(separator='')\n",
    "        texto = texto.replace('[', '')\n",
    "        texto = texto.replace(']', '')\n",
    "        return texto\n",
    "    \n",
    "    \n",
    "\n",
    "    def establecer_offset(self, offset: int):\n",
    "        \"\"\"\n",
    "        Método que estalece el OFFSET definido como el número de días a partir de la fecha\n",
    "        actual desde la que se quiere descargar los BOES\n",
    "        Si instanciamos\n",
    "        MiClase.establecer_offset(5)\n",
    "        Inspeccionaremos los BOES de hace 5 días\n",
    "        Entrada: Offset Es un etero\n",
    "        Salida: Variables internas de la clase (URLS de los BOES)\n",
    "        \"\"\"\n",
    "        fecha_calculada = self.fecha_actual - datetime.timedelta(days=offset)      \n",
    "        anio = fecha_calculada.year\n",
    "        mes = str(fecha_calculada.month).zfill(2)\n",
    "        dia = str(fecha_calculada.day).zfill(2)\n",
    "        fecha = {'anio': anio,\n",
    "                 'mes': mes,\n",
    "                 'dia': dia}        \n",
    "        self.url_busqueda = self.url_patron.substitute(anio=fecha['anio'],\n",
    "                                                       mes=fecha['mes'],\n",
    "                                                       dia=fecha['dia'])       \n",
    "\n",
    "\n",
    "\n",
    "    def buscar_urls_xmls(self):\n",
    "        \"\"\"\n",
    "        Con los parámetros obtenidos de establecer_offset, localizamos las URLS\n",
    "        de las disposiciones relativas a las ofertas de empelo público es decir \n",
    "        Sección II B del BOE\n",
    "        Uso\n",
    "        self.buscar_urls_xmls()\n",
    "        \"\"\"\n",
    "        \n",
    "        url = self.url_busqueda\n",
    "        parsed_url = urlparse(url)        \n",
    "        \n",
    "        dominio = parsed_url.netloc                \n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            html_content = response.content        \n",
    "            \n",
    "            soup = BeautifulSoup(html_content, 'html.parser')       \n",
    "            \n",
    "            titulo_buscado = \"Otros formatos\"\n",
    "                   \n",
    "            enlaces_con_titulo = soup.find_all('a', string=titulo_buscado)\n",
    "            \n",
    "            lista_urls = []\n",
    "            for enlace in enlaces_con_titulo:\n",
    "                url_obtenida = f'https://{dominio}{enlace[\"href\"]}'\n",
    "            \n",
    "                parsed_url = urlparse(url_obtenida)\n",
    "                parsed_url_lista = list(parsed_url)\n",
    "                parsed_url_lista[2] = 'diario_boe/xml.php'\n",
    "            \n",
    "                # Convertir la lista de nuevo a un objeto ParseResult\n",
    "                parsed_url_modificada = urlparse(urlunparse(parsed_url_lista))\n",
    "                lista_urls.append(urlunparse(parsed_url_modificada))\n",
    "            \n",
    "            self.lista_urls = lista_urls\n",
    "        except:\n",
    "            self.lista_urls =  []\n",
    "        \n",
    "\n",
    "    def obtener_lista_xmls(self):\n",
    "        \"\"\"\n",
    "        Con los parámetros obtenidos de establecer_offset, localizamos los XMLs\n",
    "        de las disposiciones relativas a las ofertas de empelo público es decir \n",
    "        Sección II B del BOE\n",
    "        Uso\n",
    "        self.obtener_lista_xmls()\n",
    "        \"\"\"\n",
    "        lista_respuestas = []\n",
    "        for url in self.lista_urls:\n",
    "            #url = 'https://www.boe.es/diario_boe/xml.php?id=BOE-A-2021-10344'\n",
    "            headers = {'accept': 'application/xml;q=0.9, */*;q=0.8',\n",
    "                       'User-Agent': self.user_agent}\n",
    "            try:                \n",
    "                response = requests.get(url, headers=headers, \n",
    "                                        timeout=self.timeout                                    \n",
    "                                       )\n",
    "                lista_respuestas.append(response.text)\n",
    "            except:\n",
    "                print(f\"Existe una URL {url} que no es posible descargar\")\n",
    "            \n",
    "        self.lista_xmls = lista_respuestas\n",
    "    \n",
    "    \n",
    "    def obtener_lista_titulos(self):\n",
    "        \"\"\"\n",
    "        Con los parámetros obtenidos de establecer_offset, localizamos los titulos\n",
    "        de las disposiciones relativas a las ofertas de empelo público es decir \n",
    "        Sección II B del BOE\n",
    "        Uso\n",
    "        self.obtener_lista_titulos()\n",
    "        \"\"\"\n",
    "        lista_titulos = []\n",
    "        for XML in self.lista_xmls:\n",
    "            soup = BeautifulSoup(XML, \"xml\")\n",
    "            titulo = soup.find(\"titulo\")\n",
    "            lista_titulos.append(titulo.get_text())\n",
    "        self.lista_titulos = lista_titulos\n",
    "        \n",
    "    \n",
    "    def obtener_lista_textos(self):\n",
    "        \"\"\"\n",
    "        Con los parámetros obtenidos de establecer_offset, localizamos los textos\n",
    "        de las disposiciones relativas a las ofertas de empelo público es decir \n",
    "        Sección II B del BOE\n",
    "        Uso\n",
    "        self.obtener_lista_textos()\n",
    "        \"\"\"\n",
    "        lista_textos = []\n",
    "        for XML in self.lista_xmls:\n",
    "            textos = \"\"\n",
    "            soup = BeautifulSoup(XML, \"xml\") \n",
    "            text = soup.find_all(\"texto\")           \n",
    "            lista_textos.append(str(text))\n",
    "        self.lista_textos = lista_textos\n",
    "\n",
    "    \n",
    "\n",
    "    def obtener_lista_urls_pdf(self):\n",
    "        \"\"\"\n",
    "        Con los parámetros obtenidos de establecer_offset, localizamos las urls pdfs\n",
    "        de las disposiciones relativas a las ofertas de empelo público es decir \n",
    "        Sección II B del BOE\n",
    "        Uso\n",
    "        self.obtener_lista_urls_pdf()\n",
    "        \"\"\"\n",
    "        lista_urls_pdf = []\n",
    "        for XML in self.lista_xmls:\n",
    "            textos = \"\"\n",
    "            soup = BeautifulSoup(XML, \"xml\") \n",
    "            url_pdf = soup.find_all(\"url_pdf\")           \n",
    "            lista_urls_pdf.append(f'{self.dominio}{str(self.quitar_etiquetas_html(str(url_pdf)))}')\n",
    "        self.lista_urls_pdf = lista_urls_pdf\n",
    "\n",
    "\n",
    "    def generar_dataset(self) -> int:\n",
    "        \"\"\"\n",
    "        Con los parámetros obtenidos de establecer_offset, generamos el dataset pandas\n",
    "        de las disposiciones relativas a las ofertas de empelo público es decir \n",
    "        Sección II B del BOE\n",
    "        Uso\n",
    "        self.generar_dataset()\n",
    "        Salida: Conteo de filas del dataset\n",
    "        \"\"\"\n",
    "        self.buscar_urls_xmls()\n",
    "        self.obtener_lista_xmls()\n",
    "        self.obtener_lista_titulos()\n",
    "        self.obtener_lista_textos()\n",
    "        self.obtener_lista_urls_pdf()\n",
    "        dataset_capturado = pd.DataFrame({'url':self.lista_urls_pdf, \n",
    "                                          'titulo':self.lista_titulos,\n",
    "                                          'texto':self.lista_textos})\n",
    "        \n",
    "        self.dataset_boes = pd.concat([self.dataset_boes, dataset_capturado], ignore_index=True)\n",
    "        return self.dataset_boes.shape[0]\n",
    "\n",
    "\n",
    "    def obtener_dataset_final(self):\n",
    "        \"\"\"\n",
    "        Finalmente devolvemos a la rutina principal el contenido del dataset completo\n",
    "        MiClase.obtener_dataset_final()\n",
    "        Salida: Dataset Completo\n",
    "        \"\"\"        \n",
    "        return self.dataset_boes          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c3321-089e-40df-87b4-bd85dd17195a",
   "metadata": {},
   "source": [
    "Obtenemos al menos 100 ofertas de emepleo publicadas en el BOE para facilitar busqueda de ofertas via API REST con Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded6fb19-7739-478d-bd14-98477d700184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutina principal\n",
    "N_REGISTROS_MINIMO = 100 # Limitamos a 100 las ofertas de empleo ya que si no se demora mucho\n",
    "if __name__ == \"__main__\":    \n",
    "    BOE = DescargaBOE()\n",
    "    i = 0\n",
    "    while True:      \n",
    "        BOE.establecer_offset(i)        \n",
    "        if(BOE.generar_dataset() > N_REGISTROS_MINIMO):\n",
    "            break\n",
    "        i += 1\n",
    "    BOE.obtener_dataset_final()\n",
    "\n",
    "# Obtenemos el dataset\n",
    "df = BOE.obtener_dataset_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3573e7-b224-40d7-b734-fe0b9899290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('datos_offline/datos_obtenidos.boe.csv', sep='|', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50109f-485c-4d5b-a0f5-e95b92291795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [15/Nov/2024 08:26:42] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:26:42] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:26:53] \"GET /static HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:26:57] \"GET /docs HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:27:06] \"GET /static/docs HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:27:18] \"GET /index HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:27:21] \"GET /docs/PRACTICA-ETL_Descarga_Ofertas_de_empleo_API_Flask_y_Cliente.pdf HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:27:53] \"GET /docs/Diagrama.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:29:02] \"GET /docs/PRACTICA-ETL_Descarga_Ofertas_de_empleo_API_Flask_y_Cliente.pdf HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [15/Nov/2024 08:29:51] \"GET /buscar?busqueda=Albacete HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos API Rest Flask\n",
    "# Crea una instancia de la aplicación Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Ruta para obtener la info de la peticion\n",
    "@app.route('/opciones', methods=['GET'])\n",
    "def obtener_elementos():\n",
    "    \"\"\"\n",
    "    Método de test que devuelve la cabecera de la petición en formato JSON y el User-Aget,\n",
    "    con esto se podría por ejemplo limitar las peticiones webscrapping a determinados navegadores.\n",
    "    \"\"\"\n",
    "    return jsonify({'Headers': str(request.headers),\n",
    "                    'User-agent': str(request.headers['User-Agent']),\n",
    "                    'Opciones': '1'})\n",
    "\n",
    "@app.route('/buscar', methods=['GET'])\n",
    "def buscar_oferta_empleo():\n",
    "    \"\"\"\n",
    "    Método que es ejecutado cuando se llama al API de la siguiente forma:\n",
    "    http://URL/buscar?busqueda=<Termino de Busqueda>\n",
    "    Busca y obtiene los BOES donde aparece dicho termino\n",
    "    \"\"\"\n",
    "    termino_busqueda=request.args.get('busqueda')\n",
    "    if termino_busqueda is None:\n",
    "        return jsonify({'error': 'Se requieren parametro buscar'}), 400\n",
    "    \n",
    "    # Procesar los parámetros (aquí puedes realizar cualquier lógica que desees)\n",
    "    df_resultado = df[df['texto'].str.contains(termino_busqueda)]\n",
    "    \n",
    "    # Devolver una respuesta JSON con el resultado\n",
    "    return jsonify({'url': [url for url in df_resultado['url']],\n",
    "                   'cuerpo': [texto for texto in df_resultado['texto']],\n",
    "                   'titulo': [titulo for titulo in df['titulo']]}), 200\n",
    "\n",
    "@app.route('/index')\n",
    "def estado_models():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/docs/<path:filename>')\n",
    "def imagen(filename):\n",
    "    directorio_docs = os.path.join(app.root_path, 'static', 'docs')\n",
    "    return send_from_directory(directorio_docs, filename)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292cab8-098b-4d87-8e2d-ec63f9b70d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "entorno_tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
